{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "outputHidden": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "input_file = 'inputs/19990609'\n",
    "\n",
    "def read_file(input_file: str):\n",
    "    html_text = \"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f:\n",
    "            html_text += line\n",
    "            \n",
    "    return html_text\n",
    "        \n",
    "def strip_tag(html_text: str):\n",
    "    return lxml.html.fromstring(html_text).text_content()\n",
    "\n",
    "\n",
    "def strip_symbol(content: str):\n",
    "    res = content.translate({ord(c): None for c in (\"!@#$%^&*(),./;':\\\\|<>`~\\\"”“\")})\n",
    "    return res\n",
    "\n",
    "def strip_all(html: str):\n",
    "    content = strip_tag(html)\n",
    "    content = strip_symbol(str(content).lower())\n",
    "    return content\n",
    "    \n",
    "\n",
    "html_text = read_file(input_file)\n",
    "content = strip_all(html_text)\n",
    "\n",
    "\n",
    "def str2doc(content: str):\n",
    "    return content.split()\n",
    "\n",
    "document = str2doc(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google',\n",
       " 'privacy',\n",
       " 'archived',\n",
       " 'version',\n",
       " 'privacy',\n",
       " 'policy',\n",
       " 'view',\n",
       " 'current',\n",
       " 'version',\n",
       " 'past',\n",
       " 'versions',\n",
       " 'google',\n",
       " 'sensitive',\n",
       " 'privacy',\n",
       " 'concerns',\n",
       " 'users',\n",
       " 'internet',\n",
       " 'allows',\n",
       " 'individuals',\n",
       " 'explore',\n",
       " 'communicate',\n",
       " 'unprecedented',\n",
       " 'ease',\n",
       " 'also',\n",
       " 'allows',\n",
       " 'websites',\n",
       " 'collect',\n",
       " 'distribute',\n",
       " 'personal',\n",
       " 'information',\n",
       " 'equal',\n",
       " 'ease',\n",
       " 'google',\n",
       " 'know',\n",
       " 'many',\n",
       " 'users',\n",
       " 'understandably',\n",
       " 'concerned',\n",
       " 'practices',\n",
       " 'wish',\n",
       " 'make',\n",
       " 'clear',\n",
       " 'policy',\n",
       " 'collecting',\n",
       " 'using',\n",
       " 'personal',\n",
       " 'information',\n",
       " 'google’s',\n",
       " 'policy',\n",
       " 'google’s',\n",
       " 'policy',\n",
       " 'wholly',\n",
       " 'controlled',\n",
       " 'operated',\n",
       " 'internet',\n",
       " 'sites',\n",
       " 'respect',\n",
       " 'protect',\n",
       " 'privacy',\n",
       " 'users',\n",
       " 'google',\n",
       " 'willfully',\n",
       " 'disclose',\n",
       " 'individually',\n",
       " 'identifiable',\n",
       " 'information',\n",
       " 'customers',\n",
       " 'third',\n",
       " 'party',\n",
       " 'without',\n",
       " 'first',\n",
       " 'receiving',\n",
       " 'customer’s',\n",
       " 'permission',\n",
       " 'policy',\n",
       " 'statement',\n",
       " 'tells',\n",
       " 'collect',\n",
       " 'information',\n",
       " 'google',\n",
       " 'share',\n",
       " 'information',\n",
       " 'users',\n",
       " 'advertisers',\n",
       " 'business',\n",
       " 'partners',\n",
       " 'sponsors',\n",
       " 'third',\n",
       " 'parties',\n",
       " 'however',\n",
       " 'talk',\n",
       " 'users',\n",
       " 'aggregate',\n",
       " 'individuals',\n",
       " 'example',\n",
       " 'disclose',\n",
       " 'frequently',\n",
       " 'average',\n",
       " 'google',\n",
       " 'user',\n",
       " 'visits',\n",
       " 'google',\n",
       " 'query',\n",
       " 'words',\n",
       " 'often',\n",
       " 'used',\n",
       " 'query',\n",
       " 'word',\n",
       " 'microsoft',\n",
       " 'time',\n",
       " 'time',\n",
       " 'situations',\n",
       " 'google',\n",
       " 'asks',\n",
       " 'personal',\n",
       " 'information',\n",
       " 'intend',\n",
       " 'personal',\n",
       " 'information',\n",
       " 'tell',\n",
       " 'front',\n",
       " 'decide',\n",
       " 'whether',\n",
       " 'want',\n",
       " 'give',\n",
       " 'information',\n",
       " 'case',\n",
       " 'change',\n",
       " 'mind',\n",
       " 'personal',\n",
       " 'information',\n",
       " 'changes',\n",
       " 'endeavor',\n",
       " 'provide',\n",
       " 'correct',\n",
       " 'update',\n",
       " 'remove',\n",
       " 'personal',\n",
       " 'data',\n",
       " 'give',\n",
       " 'google',\n",
       " 'cookies',\n",
       " 'upon',\n",
       " 'first',\n",
       " 'visit',\n",
       " 'google',\n",
       " 'google',\n",
       " 'sends',\n",
       " 'cookie',\n",
       " 'computer',\n",
       " 'cookie',\n",
       " 'file',\n",
       " 'identifies',\n",
       " 'unique',\n",
       " 'user',\n",
       " 'also',\n",
       " 'store',\n",
       " 'personal',\n",
       " 'preferences',\n",
       " 'user',\n",
       " 'data',\n",
       " 'cookie',\n",
       " 'tell',\n",
       " 'individual',\n",
       " 'visited',\n",
       " 'google',\n",
       " 'days',\n",
       " 'cannot',\n",
       " 'tell',\n",
       " 'person',\n",
       " 'smith',\n",
       " 'even',\n",
       " 'person',\n",
       " 'lives',\n",
       " 'united',\n",
       " 'states',\n",
       " 'google',\n",
       " 'uses',\n",
       " 'cookies',\n",
       " 'track',\n",
       " 'user',\n",
       " 'trends',\n",
       " 'patterns',\n",
       " 'order',\n",
       " 'better',\n",
       " 'understand',\n",
       " 'user',\n",
       " 'base',\n",
       " 'improve',\n",
       " 'quality',\n",
       " 'service',\n",
       " 'google',\n",
       " 'also',\n",
       " 'choose',\n",
       " 'cookies',\n",
       " 'store',\n",
       " 'user',\n",
       " 'preferences',\n",
       " 'browsers',\n",
       " 'initially',\n",
       " 'accept',\n",
       " 'cookies',\n",
       " 'reset',\n",
       " 'browser',\n",
       " 'refuse',\n",
       " 'cookies',\n",
       " 'indicate',\n",
       " 'cookie',\n",
       " 'sent',\n",
       " 'however',\n",
       " 'note',\n",
       " 'parts',\n",
       " 'google',\n",
       " 'function',\n",
       " 'properly',\n",
       " 'refuse',\n",
       " 'cookies',\n",
       " 'links',\n",
       " 'sites',\n",
       " 'page',\n",
       " 'comes',\n",
       " 'clicking',\n",
       " 'result',\n",
       " 'likely',\n",
       " 'outside',\n",
       " 'google',\n",
       " 'site',\n",
       " 'beyond',\n",
       " 'control',\n",
       " 'links',\n",
       " 'google-friends',\n",
       " 'mailing',\n",
       " 'list',\n",
       " 'archive',\n",
       " 'also',\n",
       " 'sites',\n",
       " 'controlled',\n",
       " 'google',\n",
       " 'sites',\n",
       " 'send',\n",
       " 'cookies',\n",
       " 'users',\n",
       " 'collect',\n",
       " 'data',\n",
       " 'solicit',\n",
       " 'personal',\n",
       " 'information',\n",
       " 'google',\n",
       " 'choose',\n",
       " 'exhibit',\n",
       " 'search',\n",
       " 'results',\n",
       " 'form',\n",
       " 'redirecter',\n",
       " 'redirecter',\n",
       " 'used',\n",
       " 'whenever',\n",
       " 'click',\n",
       " 'search',\n",
       " 'result',\n",
       " 'information',\n",
       " 'click',\n",
       " 'sent',\n",
       " 'google',\n",
       " 'sends',\n",
       " 'site',\n",
       " 'clicked',\n",
       " 'google',\n",
       " 'uses',\n",
       " 'information',\n",
       " 'understand',\n",
       " 'improve',\n",
       " 'quality',\n",
       " 'google’s',\n",
       " 'search',\n",
       " 'technology',\n",
       " 'instance',\n",
       " 'google',\n",
       " 'uses',\n",
       " 'information',\n",
       " 'determine',\n",
       " 'often',\n",
       " 'users',\n",
       " 'satisfied',\n",
       " 'first',\n",
       " 'result',\n",
       " 'query',\n",
       " 'often',\n",
       " 'proceed',\n",
       " 'later',\n",
       " 'results',\n",
       " 'google’s',\n",
       " 'policy',\n",
       " 'extend',\n",
       " 'anything',\n",
       " 'inherent',\n",
       " 'operation',\n",
       " 'internet',\n",
       " 'therefore',\n",
       " 'beyond',\n",
       " 'google’s',\n",
       " 'control',\n",
       " 'applied',\n",
       " 'manner',\n",
       " 'contrary',\n",
       " 'applicable',\n",
       " 'governmental',\n",
       " 'regulation',\n",
       " 'reserve',\n",
       " 'right',\n",
       " 'discretion',\n",
       " 'make',\n",
       " 'changes',\n",
       " 'policy',\n",
       " 'time',\n",
       " 'please',\n",
       " 'check',\n",
       " 'page',\n",
       " 'periodically',\n",
       " 'changes',\n",
       " 'last',\n",
       " 'updated',\n",
       " 'june']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_doc(document: list, stop_words: set):\n",
    "    res = [word for word in document if word not in stop_words and not word.isdigit() and len(word) > 3]\n",
    "    return res\n",
    "\n",
    "document = filter_doc(document, stop_words)\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element html at 0x122e139f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "html_file = \"Updates_ Privacy Policy – Privacy & Terms – Google.html\"\n",
    "html_text = \"\"\n",
    "with open(html_file, 'r') as f:\n",
    "    for line in f:\n",
    "        html_text += line\n",
    "        \n",
    "html = lxml.html.fromstring(html_text)\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://policies.google.com/privacy?hl=en&gl=CN',\n",
       " 'https://policies.google.com/privacy/archive/20180525?hl=en&gl=CN',\n",
       " 'https://policies.google.com/privacy/archive/20171218?hl=en&gl=CN',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20171002/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20170417/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20170301/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20160829/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20160628/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20160325/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20150819/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20150630/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20150605/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20150501/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20150225/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20141219/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20140331/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20131220/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20130624/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20120727/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20120301/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20111020/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20101003/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20090311/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20090127/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20080807/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20051014/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20040701/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/20010104/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/19990920/',\n",
       " 'https://www.google.com/intl/en_CN/policies/privacy/archive/19990609/']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_urls = html.xpath('//*[@id=\"archives\"]/li/a/@href')\n",
    "history_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(history_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inputs/19990609',\n",
       " 'inputs/19990920',\n",
       " 'inputs/20010104',\n",
       " 'inputs/20040701',\n",
       " 'inputs/20051014',\n",
       " 'inputs/20080807',\n",
       " 'inputs/20090127',\n",
       " 'inputs/20090311',\n",
       " 'inputs/20101003',\n",
       " 'inputs/20111020',\n",
       " 'inputs/20120301',\n",
       " 'inputs/20120727',\n",
       " 'inputs/20130624',\n",
       " 'inputs/20131220',\n",
       " 'inputs/20140331',\n",
       " 'inputs/20141219',\n",
       " 'inputs/20150225',\n",
       " 'inputs/20150501',\n",
       " 'inputs/20150605',\n",
       " 'inputs/20150630',\n",
       " 'inputs/20150819',\n",
       " 'inputs/20160325',\n",
       " 'inputs/20160628',\n",
       " 'inputs/20160829',\n",
       " 'inputs/20170301',\n",
       " 'inputs/20170417',\n",
       " 'inputs/20171002']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "inputs = \"inputs\"\n",
    "input_files = [os.path.join(inputs, input_file) for input_file in os.listdir(inputs)]\n",
    "input_files.sort()\n",
    "input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1999': 2,\n",
       "         '2001': 1,\n",
       "         '2004': 1,\n",
       "         '2005': 1,\n",
       "         '2008': 1,\n",
       "         '2009': 2,\n",
       "         '2010': 1,\n",
       "         '2011': 1,\n",
       "         '2012': 2,\n",
       "         '2013': 2,\n",
       "         '2014': 2,\n",
       "         '2015': 5,\n",
       "         '2016': 3,\n",
       "         '2017': 3})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_seq = []\n",
    "years = [input_file[-8: -4] for input_file in input_files]\n",
    "# years\n",
    "from collections import Counter\n",
    "years_count = Counter(years)\n",
    "years = list(set(years))\n",
    "years.sort()\n",
    "time_seq = [years_count[year] for year in years]\n",
    "years_count\n",
    "# time_seq.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[323,\n",
       " 322,\n",
       " 341,\n",
       " 521,\n",
       " 952,\n",
       " 1010,\n",
       " 1027,\n",
       " 1112,\n",
       " 864,\n",
       " 894,\n",
       " 1179,\n",
       " 1180,\n",
       " 1182,\n",
       " 1186,\n",
       " 1694,\n",
       " 1862,\n",
       " 1969,\n",
       " 1956,\n",
       " 2034,\n",
       " 2035,\n",
       " 2055,\n",
       " 2075,\n",
       " 2157,\n",
       " 2165,\n",
       " 2163,\n",
       " 2164,\n",
       " 2171]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "for file in input_files:\n",
    "    html_text = read_file(file)\n",
    "    content = strip_all(html_text)\n",
    "    document = str2doc(content)\n",
    "    documents.append(filter_doc(document, stop_words))\n",
    "\n",
    "# documents.append([\"test\"])\n",
    "len(documents)\n",
    "[len(document) for document in documents]\n",
    "from pprint import pprint\n",
    "# pprint(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_seq = [2, 2, 3] # total 7 documents; 2 for first, 2 for second and 3 for the last\n",
    "import os\n",
    "from gensim import corpora, utils\n",
    "from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DTMcorpus(corpora.textcorpus.TextCorpus):\n",
    "\n",
    "    def get_texts(self):\n",
    "        return self.input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "corpus = DTMcorpus(documents)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_seq = [1 for i in range(len(corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dtm_binary = \"./dtm-darwin64\"\n",
    "model = DtmModel(path_to_dtm_binary, corpus, time_seq, num_topics=1,\n",
    "                 id2word=corpus.dictionary, initialize_lda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05170207854635812, 'information'),\n",
       " (0.04740395705736623, 'google'),\n",
       " (0.02343576472049303, 'privacy'),\n",
       " (0.023218525544327424, 'services'),\n",
       " (0.02185533966186131, 'policy'),\n",
       " (0.02038793818232774, 'personal'),\n",
       " (0.012728120676553089, 'cookies'),\n",
       " (0.010372833003486409, 'provide'),\n",
       " (0.008867910286899414, 'search'),\n",
       " (0.008536922748045158, 'data')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = model.show_topic(topicid=0, time=0, topn=10)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19990609:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.05170207854635812, 'information'),\n",
       " (0.04740395705736623, 'google'),\n",
       " (0.02343576472049303, 'privacy'),\n",
       " (0.023218525544327424, 'services'),\n",
       " (0.02185533966186131, 'policy'),\n",
       " (0.02038793818232774, 'personal'),\n",
       " (0.012728120676553089, 'cookies'),\n",
       " (0.010372833003486409, 'provide'),\n",
       " (0.008867910286899414, 'search'),\n",
       " (0.008536922748045158, 'data')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19990920:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.052373381030124476, 'information'),\n",
       " (0.04633369562442682, 'google'),\n",
       " (0.0239086431642587, 'privacy'),\n",
       " (0.023701882935210753, 'services'),\n",
       " (0.021893453948065973, 'policy'),\n",
       " (0.020515270351871274, 'personal'),\n",
       " (0.012549521277511664, 'cookies'),\n",
       " (0.010491355484645665, 'provide'),\n",
       " (0.008725422694271725, 'search'),\n",
       " (0.008577531650975107, 'data')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20010104:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.053364870100181816, 'information'),\n",
       " (0.04423621197452928, 'google'),\n",
       " (0.024728905666645498, 'privacy'),\n",
       " (0.0245461442125542, 'services'),\n",
       " (0.021894573323109574, 'policy'),\n",
       " (0.020959406567880163, 'personal'),\n",
       " (0.012185436745132831, 'cookies'),\n",
       " (0.01068266223171738, 'provide'),\n",
       " (0.008668898281550583, 'data'),\n",
       " (0.008348161151134806, 'search')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20040701:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.05436467774394938, 'information'),\n",
       " (0.04164097886433799, 'google'),\n",
       " (0.02585269334177613, 'privacy'),\n",
       " (0.025651772277761994, 'services'),\n",
       " (0.02186391704532256, 'personal'),\n",
       " (0.02182506979920219, 'policy'),\n",
       " (0.011671921241861616, 'cookies'),\n",
       " (0.010892205414965554, 'provide'),\n",
       " (0.008783079195400131, 'data'),\n",
       " (0.0077646647707025635, 'search')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20051014:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.054908183942053185, 'information'),\n",
       " (0.03939688410031317, 'google'),\n",
       " (0.027198177900460703, 'privacy'),\n",
       " (0.026870382191458455, 'services'),\n",
       " (0.023036264291387117, 'personal'),\n",
       " (0.021645577487275098, 'policy'),\n",
       " (0.011114679553722123, 'cookies'),\n",
       " (0.01102732584351851, 'provide'),\n",
       " (0.008859387537140143, 'data'),\n",
       " (0.007897005822912638, 'access')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20080807:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.055167152223417365, 'information'),\n",
       " (0.03787247235844962, 'google'),\n",
       " (0.028466321612283147, 'privacy'),\n",
       " (0.028099848369332766, 'services'),\n",
       " (0.023565713538131895, 'personal'),\n",
       " (0.021279810659316088, 'policy'),\n",
       " (0.011012090762144953, 'provide'),\n",
       " (0.010637756699719529, 'cookies'),\n",
       " (0.008826708048803587, 'data'),\n",
       " (0.008179209131006214, 'access')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20090127:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.055519557912715366, 'information'),\n",
       " (0.0370990533149999, 'google'),\n",
       " (0.029253350627996666, 'services'),\n",
       " (0.028881544769505278, 'privacy'),\n",
       " (0.023162061231061657, 'personal'),\n",
       " (0.02067826982399923, 'policy'),\n",
       " (0.010830430070196377, 'provide'),\n",
       " (0.0102453505431373, 'cookies'),\n",
       " (0.008667678963003064, 'data'),\n",
       " (0.00844210876973902, 'access')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20090311:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.05623264792890052, 'information'),\n",
       " (0.0368939472421249, 'google'),\n",
       " (0.03022987286152491, 'services'),\n",
       " (0.028179649813337503, 'privacy'),\n",
       " (0.02188209996272668, 'personal'),\n",
       " (0.019825671188083212, 'policy'),\n",
       " (0.010497933055409388, 'provide'),\n",
       " (0.009916451851256808, 'cookies'),\n",
       " (0.008674769228376686, 'access'),\n",
       " (0.008378012850610789, 'data')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20101003:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.057518729166491554, 'information'),\n",
       " (0.036880055514647785, 'google'),\n",
       " (0.030908927941643474, 'services'),\n",
       " (0.02656886323159088, 'privacy'),\n",
       " (0.020080498849040573, 'personal'),\n",
       " (0.01874248827614072, 'policy'),\n",
       " (0.0100582783587155, 'provide'),\n",
       " (0.00961725749691335, 'cookies'),\n",
       " (0.008864622835512013, 'access'),\n",
       " (0.00845798860796072, 'account')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20111020:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.05934583061025046, 'information'),\n",
       " (0.03672555481737089, 'google'),\n",
       " (0.031213942548916296, 'services'),\n",
       " (0.02465962904242076, 'privacy'),\n",
       " (0.0184009654407863, 'personal'),\n",
       " (0.017506172492059494, 'policy'),\n",
       " (0.009573086847595544, 'provide'),\n",
       " (0.009315633801425614, 'cookies'),\n",
       " (0.009150498894999555, 'account'),\n",
       " (0.008980006390851456, 'access')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120301:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0613010053873633, 'information'),\n",
       " (0.03643568606208242, 'google'),\n",
       " (0.03112388287555434, 'services'),\n",
       " (0.02278708000566524, 'privacy'),\n",
       " (0.016966102417994487, 'personal'),\n",
       " (0.016216421233512798, 'policy'),\n",
       " (0.009866428459453154, 'account'),\n",
       " (0.009083252705039669, 'provide'),\n",
       " (0.009015902340835385, 'access'),\n",
       " (0.009011583299838215, 'cookies')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120727:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.06234303117822188, 'information'),\n",
       " (0.0363222542452417, 'google'),\n",
       " (0.030659205968242103, 'services'),\n",
       " (0.02117036562631149, 'privacy'),\n",
       " (0.01581112232870957, 'personal'),\n",
       " (0.014998014034593691, 'policy'),\n",
       " (0.010530352438272965, 'account'),\n",
       " (0.010342867918980873, 'example'),\n",
       " (0.009082110660037074, 'including'),\n",
       " (0.0089881872623115, 'access')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20130624:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0619964790301147, 'information'),\n",
       " (0.036564886046659646, 'google'),\n",
       " (0.029884345046595345, 'services'),\n",
       " (0.01979565479508816, 'privacy'),\n",
       " (0.014841996652788198, 'personal'),\n",
       " (0.013889504504869466, 'policy'),\n",
       " (0.012543233895939082, 'example'),\n",
       " (0.011126642764538647, 'account'),\n",
       " (0.009373732529681269, 'including'),\n",
       " (0.009058549572685703, 'collect')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20131220:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.06026663859181569, 'information'),\n",
       " (0.0372324969486672, 'google'),\n",
       " (0.028891031745047906, 'services'),\n",
       " (0.018584741834064066, 'privacy'),\n",
       " (0.015396280525797494, 'example'),\n",
       " (0.013969718341840994, 'personal'),\n",
       " (0.012891508616070926, 'policy'),\n",
       " (0.0116715847604895, 'account'),\n",
       " (0.009562028194648648, 'including'),\n",
       " (0.009164841212196597, 'collect')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20140331:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.05762647240963009, 'information'),\n",
       " (0.03828334879507095, 'google'),\n",
       " (0.02780054061056166, 'services'),\n",
       " (0.018940587081452284, 'example'),\n",
       " (0.017483168174724346, 'privacy'),\n",
       " (0.013171608160585657, 'personal'),\n",
       " (0.012192672351620474, 'account'),\n",
       " (0.011999909815189263, 'policy'),\n",
       " (0.00966115451116651, 'including'),\n",
       " (0.009164180947994188, 'collect')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20141219:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.05505288892969461, 'information'),\n",
       " (0.039578858551934507, 'google'),\n",
       " (0.02678476441489113, 'services'),\n",
       " (0.022807850939209385, 'example'),\n",
       " (0.016517365351710556, 'privacy'),\n",
       " (0.012716603700270593, 'account'),\n",
       " (0.012543504525880825, 'personal'),\n",
       " (0.011231067673365085, 'policy'),\n",
       " (0.0097049710470955, 'including'),\n",
       " (0.00959297975294978, 'learn')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150225:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.05299492618525315, 'information'),\n",
       " (0.04097164325592383, 'google'),\n",
       " (0.026307401316236732, 'example'),\n",
       " (0.025945193899365677, 'services'),\n",
       " (0.01571032583580174, 'privacy'),\n",
       " (0.013250961299985433, 'account'),\n",
       " (0.012054458413567804, 'personal'),\n",
       " (0.010929967274551065, 'learn'),\n",
       " (0.010596126516293523, 'policy'),\n",
       " (0.009695577141964371, 'including')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150501:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.051533718271182714, 'information'),\n",
       " (0.0422469481753091, 'google'),\n",
       " (0.029045594641623994, 'example'),\n",
       " (0.02532825831663604, 'services'),\n",
       " (0.015076883137292845, 'privacy'),\n",
       " (0.013765860098728707, 'account'),\n",
       " (0.012053807367415717, 'learn'),\n",
       " (0.011673280274515913, 'personal'),\n",
       " (0.01009203124071152, 'policy'),\n",
       " (0.00965448474616833, 'including')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150605:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.05064752886577626, 'information'),\n",
       " (0.04324589615284377, 'google'),\n",
       " (0.03092515237272403, 'example'),\n",
       " (0.024934729909977735, 'services'),\n",
       " (0.014620255986541007, 'privacy'),\n",
       " (0.014243658634535552, 'account'),\n",
       " (0.012995509064479455, 'learn'),\n",
       " (0.011380856721559349, 'personal'),\n",
       " (0.009703114682017587, 'policy'),\n",
       " (0.009595790506993737, 'including')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150630:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.05009529551436011, 'information'),\n",
       " (0.04395847646116376, 'google'),\n",
       " (0.0320063414151115, 'example'),\n",
       " (0.024754385894967746, 'services'),\n",
       " (0.014637537228131605, 'account'),\n",
       " (0.014326215987464084, 'privacy'),\n",
       " (0.013745041456304941, 'learn'),\n",
       " (0.01115377932530377, 'personal'),\n",
       " (0.009537208048941273, 'including'),\n",
       " (0.0094075366732092, 'policy')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150819:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.04966840798850737, 'information'),\n",
       " (0.044448694443797086, 'google'),\n",
       " (0.03249770334912015, 'example'),\n",
       " (0.024755179089205083, 'services'),\n",
       " (0.014950896175783894, 'account'),\n",
       " (0.014277650359440812, 'learn'),\n",
       " (0.014152781558004784, 'privacy'),\n",
       " (0.010980470580612913, 'personal'),\n",
       " (0.009486466127467525, 'including'),\n",
       " (0.009184004898271527, 'policy')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160325:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.04925579599351591, 'information'),\n",
       " (0.04478322380819817, 'google'),\n",
       " (0.032634316230273956, 'example'),\n",
       " (0.02488752723948258, 'services'),\n",
       " (0.01520331911370784, 'account'),\n",
       " (0.014631543817631985, 'learn'),\n",
       " (0.014041077040390648, 'privacy'),\n",
       " (0.010872020914438237, 'personal'),\n",
       " (0.009447654033509069, 'including'),\n",
       " (0.009014802101529865, 'policy')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160628:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.04884454326809214, 'information'),\n",
       " (0.044999344836953205, 'google'),\n",
       " (0.03260673574651408, 'example'),\n",
       " (0.025096215588895167, 'services'),\n",
       " (0.015396159788374554, 'account'),\n",
       " (0.014859391408375586, 'learn'),\n",
       " (0.013966540515958631, 'privacy'),\n",
       " (0.010819916201129574, 'personal'),\n",
       " (0.009424528163765544, 'including'),\n",
       " (0.008887956042680402, 'policy')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160829:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.04851313499479124, 'information'),\n",
       " (0.04507929633925645, 'google'),\n",
       " (0.03254089659256503, 'example'),\n",
       " (0.025324444791139104, 'services'),\n",
       " (0.015527345813476947, 'account'),\n",
       " (0.01500604950481723, 'learn'),\n",
       " (0.013926964081356307, 'privacy'),\n",
       " (0.010792170718511268, 'personal'),\n",
       " (0.00942139702985288, 'including'),\n",
       " (0.008797615022626428, 'policy')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170301:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.04828547056404339, 'information'),\n",
       " (0.04506782952072086, 'google'),\n",
       " (0.03249356551852848, 'example'),\n",
       " (0.025534321028159654, 'services'),\n",
       " (0.015610041678110781, 'account'),\n",
       " (0.01510014897494476, 'learn'),\n",
       " (0.013906017268683775, 'privacy'),\n",
       " (0.01077593764133583, 'personal'),\n",
       " (0.009427331294944878, 'including'),\n",
       " (0.008737692138911743, 'policy')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170417:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.04814890240841707, 'information'),\n",
       " (0.04504342098486236, 'google'),\n",
       " (0.032473391755756614, 'example'),\n",
       " (0.02569672174181504, 'services'),\n",
       " (0.015657156030327773, 'account'),\n",
       " (0.015155350296379978, 'learn'),\n",
       " (0.013895086579157659, 'privacy'),\n",
       " (0.010765578611032736, 'personal'),\n",
       " (0.009435385008846673, 'including'),\n",
       " (0.008705624171612546, 'like')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171002:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.04808603824669193, 'information'),\n",
       " (0.045037431894413046, 'google'),\n",
       " (0.032470511457592374, 'example'),\n",
       " (0.025788093053724995, 'services'),\n",
       " (0.015678759411929984, 'account'),\n",
       " (0.015180438252064684, 'learn'),\n",
       " (0.013890428980511705, 'privacy'),\n",
       " (0.010759967445992955, 'personal'),\n",
       " (0.009441128972282536, 'including'),\n",
       " (0.008744305853910672, 'like')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    for j in range(len(time_seq)):\n",
    "        print(input_files[j].split(\"/\")[-1] + \":\")\n",
    "        model.show_topic(i, j, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gamma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_model = DtmModel(path_to_dtm_binary, corpus, time_seq, num_topics=1,\n",
    "                 id2word=corpus.dictionary, initialize_lda=True, model='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.04487017]]),\n",
       " array([[0.00755651]]),\n",
       " array([[0.01054809]]),\n",
       " array([[0.03098739]]),\n",
       " array([[0.08948956]]),\n",
       " array([[0.00262296]]),\n",
       " array([[-0.00572049]]),\n",
       " array([[0.02206943]]),\n",
       " array([[-0.00018109]]),\n",
       " array([[0.04982455]]),\n",
       " array([[0.09681206]]),\n",
       " array([[0.02833254]]),\n",
       " array([[-0.01311693]]),\n",
       " array([[-0.02827837]]),\n",
       " array([[0.04643593]]),\n",
       " array([[0.07417891]]),\n",
       " array([[0.04799896]]),\n",
       " array([[0.02677942]]),\n",
       " array([[0.04160749]]),\n",
       " array([[0.03504583]]),\n",
       " array([[0.04164879]]),\n",
       " array([[0.03966195]]),\n",
       " array([[0.03814424]]),\n",
       " array([[0.02960172]]),\n",
       " array([[0.01487303]]),\n",
       " array([[0.00038175]]),\n",
       " array([[0.]])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_no = 1 #document 2\n",
    "topic_no = 0 #topic number 1\n",
    "time_slice = 0 #time slice 1\n",
    "\n",
    "type(dim_model.influences_time)\n",
    "dim_model.influences_time\n",
    "\n",
    "# for document_no in range(len(corpus)):\n",
    "# for time_slice in range(len(time_seq)):\n",
    "#    dim_model.influences_time[time_slice][document_no][topic_no]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DtmModel in module gensim.models.wrappers.dtmmodel object:\n",
      "\n",
      "class DtmModel(gensim.utils.SaveLoad)\n",
      " |  Python wrapper using `DTM implementation <https://github.com/magsilva/dtm/tree/master/bin>`_.\n",
      " |  \n",
      " |  Communication between DTM and Python takes place by passing around data files on disk and executing\n",
      " |  the DTM binary as a subprocess.\n",
      " |  \n",
      " |  Warnings\n",
      " |  --------\n",
      " |  This is **only** python wrapper for `DTM implementation <https://github.com/magsilva/dtm/tree/master/bin>`_,\n",
      " |  you need to install original implementation first and pass the path to binary to ``dtm_path``.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DtmModel\n",
      " |      gensim.utils.SaveLoad\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dtm_path, corpus=None, time_slices=None, mode='fit', model='dtm', num_topics=100, id2word=None, prefix=None, lda_sequence_min_iter=6, lda_sequence_max_iter=20, lda_max_em_iter=10, alpha=0.01, top_chain_var=0.005, rng_seed=0, initialize_lda=True)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtm_path : str\n",
      " |          Path to the dtm binary, e.g. `/home/username/dtm/dtm/main`.\n",
      " |      corpus : iterable of iterable of (int, int)\n",
      " |          Collection of texts in BoW format.\n",
      " |      time_slices : list of int\n",
      " |          Sequence of timestamps.\n",
      " |      mode : {'fit', 'time'}, optional\n",
      " |          Controls the mode of the mode: 'fit' is for training, 'time' for analyzing documents through time\n",
      " |          according to a DTM, basically a held out set.\n",
      " |      model : {'fixed', 'dtm'}, optional\n",
      " |          Control model that will be runned: 'fixed' is for DIM and 'dtm' for DTM.\n",
      " |      num_topics : int, optional\n",
      " |          Number of topics.\n",
      " |      id2word : :class:`~gensim.corpora.dictionary.Dictionary`, optional\n",
      " |          Mapping between tokens ids and words from corpus, if not specified - will be inferred from `corpus`.\n",
      " |      prefix : str, optional\n",
      " |          Prefix for produced temporary files.\n",
      " |      lda_sequence_min_iter : int, optional\n",
      " |           Min iteration of LDA.\n",
      " |      lda_sequence_max_iter : int, optional\n",
      " |          Max iteration of LDA.\n",
      " |      lda_max_em_iter : int, optional\n",
      " |           Max em optimization iterations in LDA.\n",
      " |      alpha : int, optional\n",
      " |          Hyperparameter that affects sparsity of the document-topics for the LDA models in each timeslice.\n",
      " |      top_chain_var : int, optional\n",
      " |          Hyperparameter that affects.\n",
      " |      rng_seed : int, optional\n",
      " |           Random seed.\n",
      " |      initialize_lda : bool, optional\n",
      " |           If True - initialize DTM with LDA.\n",
      " |  \n",
      " |  convert_input(self, corpus, time_slices)\n",
      " |      Convert corpus into LDA-C format by :class:`~gensim.corpora.bleicorpus.BleiCorpus` and save to temp file.\n",
      " |      Path to temporary file produced by :meth:`~gensim.models.wrappers.dtmmodel.DtmModel.ftimeslices`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of iterable of (int, float)\n",
      " |          Corpus in BoW format.\n",
      " |      time_slices : list of int\n",
      " |          Sequence of timestamps.\n",
      " |  \n",
      " |  dtm_coherence(self, time, num_words=20)\n",
      " |      Get all topics of a particular time-slice without probability values for it to be used.\n",
      " |      For either \"u_mass\" or \"c_v\" coherence.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_words : int\n",
      " |          Number of words.\n",
      " |      time : int\n",
      " |          Timestamp\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      coherence_topics : list of list of str\n",
      " |          All topics of a particular time-slice without probability values for it to be used.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      TODO: because of print format right now can only return for 1st time-slice, should we fix the coherence\n",
      " |      printing or make changes to the print statements to mirror DTM python?\n",
      " |  \n",
      " |  dtm_vis(self, corpus, time)\n",
      " |      Get data specified by pyLDAvis format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of iterable of (int, float)\n",
      " |          Collection of texts in BoW format.\n",
      " |      time : int\n",
      " |          Sequence of timestamp.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      All of these are needed to visualise topics for DTM for a particular time-slice via pyLDAvis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      doc_topic : numpy.ndarray\n",
      " |          Document-topic proportions.\n",
      " |      topic_term : numpy.ndarray\n",
      " |          Calculated term of topic suitable for pyLDAvis format.\n",
      " |      doc_lengths : list of int\n",
      " |          Length of each documents in corpus.\n",
      " |      term_frequency : numpy.ndarray\n",
      " |          Frequency of each word from vocab.\n",
      " |      vocab : list of str\n",
      " |          List of words from docpus.\n",
      " |  \n",
      " |  fcorpus(self)\n",
      " |      Get path to corpus file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to corpus file.\n",
      " |  \n",
      " |  fcorpustxt(self)\n",
      " |      Get path to temporary file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to multiple train binary file.\n",
      " |  \n",
      " |  fem_steps(self)\n",
      " |      Get path to temporary em_step data file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to em_step data file.\n",
      " |  \n",
      " |  finit_alpha(self)\n",
      " |      Get path to initially trained lda alpha file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to initially trained lda alpha file.\n",
      " |  \n",
      " |  finit_beta(self)\n",
      " |      Get path to initially trained lda beta file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to initially trained lda beta file.\n",
      " |  \n",
      " |  flda_ss(self)\n",
      " |      Get path to initial lda binary file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to initial lda binary file.\n",
      " |  \n",
      " |  fout_gamma(self)\n",
      " |      Get path to temporary gamma data file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to gamma data file.\n",
      " |  \n",
      " |  fout_influence(self)\n",
      " |      Get template of path to temporary file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to file.\n",
      " |  \n",
      " |  fout_liklihoods(self)\n",
      " |      Get path to temporary lhood data file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to lhood data file.\n",
      " |  \n",
      " |  fout_observations(self)\n",
      " |      Get template of path to temporary file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to file.\n",
      " |  \n",
      " |  fout_prob(self)\n",
      " |      Get template of path to temporary file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to file.\n",
      " |  \n",
      " |  foutname(self)\n",
      " |      Get path to temporary file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to file.\n",
      " |  \n",
      " |  ftimeslices(self)\n",
      " |      Get path to time slices binary file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Path to time slices binary file.\n",
      " |  \n",
      " |  print_topic(self, topicid, time, topn=10, num_words=None)\n",
      " |      Get the given topic, formatted as a string.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicid : int\n",
      " |          Id of topic.\n",
      " |      time : int\n",
      " |          Timestamp.\n",
      " |      topn : int, optional\n",
      " |          Top number of topics that you'll receive.\n",
      " |      num_words : int, optional\n",
      " |          DEPRECATED PARAMETER, use `topn` instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          The given topic in string format, like '0.132*someword + 0.412*otherword + ...'.\n",
      " |  \n",
      " |  print_topics(self, num_topics=10, times=5, num_words=10)\n",
      " |      Alias for :meth:`~gensim.models.wrappers.dtmmodel.DtmModel.show_topics`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          Number of topics to return, set `-1` to get all topics.\n",
      " |      times : int, optional\n",
      " |          Number of times.\n",
      " |      num_words : int, optional\n",
      " |          Number of words.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of str\n",
      " |          Topics as a list of strings\n",
      " |  \n",
      " |  show_topic(self, topicid, time, topn=50, num_words=None)\n",
      " |      Get `num_words` most probable words for the given `topicid`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicid : int\n",
      " |          Id of topic.\n",
      " |      time : int\n",
      " |          Timestamp.\n",
      " |      topn : int, optional\n",
      " |          Top number of topics that you'll receive.\n",
      " |      num_words : int, optional\n",
      " |          DEPRECATED PARAMETER, use `topn` instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (float, str)\n",
      " |          Sequence of probable words, as a list of `(word_probability, word)`.\n",
      " |  \n",
      " |  show_topics(self, num_topics=10, times=5, num_words=10, log=False, formatted=True)\n",
      " |      Get the `num_words` most probable words for `num_topics` number of topics at 'times' time slices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          Number of topics to return, set `-1` to get all topics.\n",
      " |      times : int, optional\n",
      " |          Number of times.\n",
      " |      num_words : int, optional\n",
      " |          Number of words.\n",
      " |      log : bool, optional\n",
      " |          THIS PARAMETER WILL BE IGNORED.\n",
      " |      formatted : bool, optional\n",
      " |          If `True` - return the topics as a list of strings, otherwise as lists of (weight, word) pairs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of str\n",
      " |          Topics as a list of strings (if formatted=True) **OR**\n",
      " |      list of (float, str)\n",
      " |          Topics as list of (weight, word) pairs (if formatted=False)\n",
      " |  \n",
      " |  train(self, corpus, time_slices, mode, model)\n",
      " |      Train DTM model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of iterable of (int, int)\n",
      " |          Collection of texts in BoW format.\n",
      " |      time_slices : list of int\n",
      " |          Sequence of timestamps.\n",
      " |      mode : {'fit', 'time'}, optional\n",
      " |          Controls the mode of the mode: 'fit' is for training, 'time' for analyzing documents through time\n",
      " |          according to a DTM, basically a held out set.\n",
      " |      model : {'fixed', 'dtm'}, optional\n",
      " |          Control model that will be runned: 'fixed' is for DIM and 'dtm' for DTM.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  save(self, fname_or_handle, separately=None, sep_limit=10485760, ignore=frozenset(), pickle_protocol=2)\n",
      " |      Save the object to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname_or_handle : str or file-like\n",
      " |          Path to output file or already opened file-like object. If the object is a file handle,\n",
      " |          no special array handling will be performed, all attributes will be saved to the same file.\n",
      " |      separately : list of str or None, optional\n",
      " |          If None, automatically detect large numpy/scipy.sparse arrays in the object being stored, and store\n",
      " |          them into separate files. This prevent memory errors for large objects, and also allows\n",
      " |          `memory-mapping <https://en.wikipedia.org/wiki/Mmap>`_ the large arrays for efficient\n",
      " |          loading and sharing the large arrays in RAM between multiple processes.\n",
      " |      \n",
      " |          If list of str: store these attributes into separate files. The automated size check\n",
      " |          is not performed in this case.\n",
      " |      sep_limit : int, optional\n",
      " |          Don't store arrays smaller than this separately. In bytes.\n",
      " |      ignore : frozenset of str, optional\n",
      " |          Attributes that shouldn't be stored at all.\n",
      " |      pickle_protocol : int, optional\n",
      " |          Protocol number for pickle.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.utils.SaveLoad.load`\n",
      " |          Load object from file.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  load(fname, mmap=None) from builtins.type\n",
      " |      Load an object previously saved using :meth:`~gensim.utils.SaveLoad.save` from a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to file that contains needed object.\n",
      " |      mmap : str, optional\n",
      " |          Memory-map option.  If the object was saved with large arrays stored separately, you can load these arrays\n",
      " |          via mmap (shared memory) using `mmap='r'.\n",
      " |          If the file being loaded is compressed (either '.gz' or '.bz2'), then `mmap=None` **must be** set.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.utils.SaveLoad.save`\n",
      " |          Save object to file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object\n",
      " |          Object loaded from `fname`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          When called on an object instance instead of class (this is a class method).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "influences = [round(max(i)[0], 4) for i in dim_model.influences_time]\n",
    "influences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "outputExpanded": true,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from pyecharts import Line\n",
    "\n",
    "line = Line(\"Influences\")\n",
    "years = [i for i in range(len(influences))]\n",
    "line.add(\"Google's policies\", years, influences, mark_point=['max'], mark_point_symbol='arrow')\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = [documents[4] for i in range(10)]\n",
    "test_corpus = DTMcorpus(test_documents)\n",
    "test_time_seq = [1] * 10\n",
    "test_dim_model = DtmModel(path_to_dtm_binary, test_corpus, test_time_seq, num_topics=1,\n",
    "                 id2word=test_corpus.dictionary, initialize_lda=True, model='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.38547742]]),\n",
       " array([[0.15435206]]),\n",
       " array([[0.05475012]]),\n",
       " array([[0.02807272]]),\n",
       " array([[0.02779628]]),\n",
       " array([[0.02951287]]),\n",
       " array([[0.02450806]]),\n",
       " array([[0.01139932]]),\n",
       " array([[0.00020762]]),\n",
       " array([[0.]])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dim_model.influences_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confused\n",
    "\n",
    "Why `influences_time` varies with exactly **identical** documents?\n",
    "And it decreases?\n",
    "\n",
    "# Possible Explanation\n",
    "\n",
    "`time slice` may be taken into consideration\n",
    "\n",
    "# According the paper\n",
    "\n",
    "## Screenshots:\n",
    "\n",
    "---\n",
    "<img src=\"https://ws4.sinaimg.cn/large/006tKfTcgy1g0ogsc25abj30ry05cgmx.jpg\" width=\"400px\"/>\n",
    "\n",
    "---\n",
    "<img src=\"https://ws2.sinaimg.cn/large/006tKfTcgy1g0ogziwu7zj30yo07qmyq.jpg\" width=\"400dip\"/>\n",
    "\n",
    "where $\\tilde{m}_{t+1}$ stands for the mean value of topic trajectory $\\tilde{\\beta}_{k, t}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_test_documents = [[\"前天晚上做梦，梦见和大猫、大儒、小三、静静以及帆神一起在KTV里唱歌。这是个再寻常不过的场景，因为两周以前的周五我们一行六人就一同去唱过歌。但是在梦里，我们以一人唱一小段的方式一起唱的一首歌词很棒、旋律也非常好听的歌，引起了我的注意。梦里的我意识到自己是在做梦了，于是开始在梦里思考，这首好听的歌究竟是显示中存在的歌，还是我的潜意识在梦里自行创作出来的歌呢？如果是后者的话，若将这歌词记录下来岂不妙哉？于是梦里的我经过仔细的思考判断，认为是一首现实中存在的歌，因此记录歌词之事不了了之。\"],[\"醒来之后的我，忆起梦中之事，却无论如何也记不起这首被梦中的我认定是现实中存在的歌究竟叫什么名字。甚至对于梦中隐约记得的旋律，也感觉颇为陌生。这首歌莫不是真是我梦中所作？怀着怅然若失的感觉，我开始仔细回忆梦里的一些细节。最后只记得一星半点：轮到我唱的那一段似乎恰好是副歌部分，而且有一句歌词有“杯中”的字眼，末尾的字不记得是“古”还是“口”了。面对这样的线索，我更惆怅了，因为印象里自己没听过这样的歌曲，可能是真的错失了梦中所作的歌吧！\"], [\"昨天夜里，躺在床上，像往常一样打开网易云音乐准备边听歌边睡觉的我，突然想起一件至关重要的事情：前天夜里我是听着网易云的私人FM睡觉的！也许梦里的歌就在其中！怀揣着这样的念头，我不停地在听歌记录里翻找符合条件的歌。功夫不负有心人，最后终于找到一首副歌开头部分是“熬到结局，杯中酒剩一口”的歌——音阙诗听的《我已经走到了幻想尽头》。经过反复的播放，我确信这旋律正是梦中的旋律，这首歌正是出现在我梦中的那首歌。\\\n",
    "历经此番寻梦，不由得感叹：网易云音乐，一款能将音乐带到我梦里的播放器；音阙诗听，一个能将歌曲唱到我梦里的音乐社团；《我已经走到了幻想尽头》，一首闯入我梦境的歌。\"]]\n",
    "another_test_corpus = DTMcorpus(another_test_documents)\n",
    "another_test_time_seq = [1] * len(another_test_documents)\n",
    "another_test_dim_model = DtmModel(path_to_dtm_binary, another_test_corpus, another_test_time_seq, num_topics=1,\n",
    "                 id2word=another_test_corpus.dictionary, initialize_lda=True, model='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00486905]]), array([[6.17762782e-05]]), array([[0.]])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_test_dim_model.influences_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div></div>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml.html.clean import Cleaner\n",
    "cleaner = Cleaner(page_structure=True,\n",
    "                  meta=True,\n",
    "                  embedded=True,\n",
    "                  links=True,\n",
    "                  style=True,\n",
    "                  processing_instructions=True,\n",
    "                  inline_style=True,\n",
    "                  scripts=True,\n",
    "                  javascript=True,\n",
    "                  comments=True,\n",
    "                  frames=True,\n",
    "                  forms=True,\n",
    "                  annoying_tags=True,\n",
    "                  remove_unknown_tags=True,\n",
    "                  remove_tags=('span', 'font', 'div', 'p')\n",
    "                 )\n",
    "test_html = \"\"\"<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );</script>\"\"\"\n",
    "cleaner.clean_html(test_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml.html.clean import clean_html\n",
    "lxml.html.fromstring(clean_html(test_html)).text_content()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "graduationproject"
  },
  "kernelspec": {
   "display_name": "GraduationProject",
   "language": "python",
   "name": "graduationproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
